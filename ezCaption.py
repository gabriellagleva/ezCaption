import pygame
from sys import exit
from faster_whisper import WhisperModel
import textwrap 
import pyaudio
import numpy as np
import wave
import threading 
import time
import audioop



#Buffer to hold all text info
buffer = []

#Lock to ensure that 
lock = threading.Lock()

            
#Recording thread
def record(buffer: list):

    '''
    Copyright Notice / Disclaimer:
    Portions of the following code was inspired by:
    https://github.com/Uberi/speech_recognition#readme, particularly the use of audioop.rms

    Portions of the following code was generated by:
    Chatgpt
    
    '''

    #Pyaudio imported so that the thread still has access to it

    import pyaudio

    sample_format = pyaudio.paInt16 
    channels = 1 
    sample_rate = 44100 
    chunksize = 4096 

    # Initialize PyAudio object
    p = pyaudio.PyAudio()
    # Open stream
    stream = p.open(format=pyaudio.paInt16,
                    channels=channels,
                    rate=sample_rate,
                    frames_per_buffer=chunksize,
                    input=True,
                    input_device_index=0)

    #Temporary buffer to hold all info from the recording thread until it has a chance to put its recordings in the global buffer
    tempbuffer = []


    #While True loop ensures the program runs until it is completely stopped
    while True:


        counter = 0
        isSilentBegin = False
        is_recording = False

        while not isSilentBegin:
            
            #Records data from pyaudio
            data = stream.read(chunksize)


            '''
            Following if statement acts as an inital threshold for the audio. Recording will not be saved unless it detects a rms higher than 350, or is_recording is true. Afterwards, is_recording is set to true to allow for audio that is quieter than 350 to be recorded
            '''
            if audioop.rms(data, 2) < 350 and is_recording == False :

                #Continue resets loop if the two conditions are met
                continue
        
            #Once a audio greater than 350 is detected, is_recording is set to true to allow for recording less than 350
            is_recording = True


            #Adds info to buffer so long as it is not quieter than 100 or louder than 7500. 7500 tends to be breathing into the microphone or hitting it, so its likely not useful info. 100 and less is likley keyboard typing or ambient noise. These thresholds may need to be changed for your system.
            if audioop.rms(data, 2) > 100 and audioop.rms(data, 2) < 7500:

                tempbuffer.append(data)

                #Resets counter, as the user has likely begun talking again

                counter = 0

            #counter + 1 if too quiet or too loud
            else:

                counter += 1
            
            #Counter counts the number of times that "too quiet" or "too loud" has been detected. If it is detected 3 times in a row, the while loop breaks, as the program will assume the user stopped talking
            if counter == 3:

                isSilentBegin = True

        #Will aquiure the lock and put the temp buffer in it, assuming that the temp buffer is not empty
        if not lock.locked() and len(tempbuffer) >1:

            lock.acquire()

            try:

                buffer.extend(tempbuffer)
                tempbuffer.clear()

            except Exception as error:

                print(error)

            finally:

                lock.release()


'Creates both threads'
t2= threading.Thread(target = record, args = [buffer])

'Actually starts both threads'

t2.start()


'''
Pygame thread lives here. 
Through my testing, I determined that pygame only likes to run on the main thread for some unknown reason, so here it is :shrug:
'''

#For Pygame to work, it neeeds to be init'd with a screen.  
pygame.init()
screen = pygame.display.set_mode((800,800))
background = pygame.Surface((800,800))

#Green background allows for chromakeying out. 
background.fill("Green")


font_set = pygame.font.Font("C:\WINDOWS\Fonts\\ntailu.ttf", 25)
font_set.bold

pygame.display.set_caption('Transcription')
clock = pygame.time.Clock()

#Our whisper model, isn't she lovely ^_^ Feel free to mess around with these settings. Optimal will depend on your local machine
model = WhisperModel("small", device="cuda", compute_type = 'int8')


sample_format = pyaudio.paInt16 
channels = 1 
sample_rate = 44100 
chunksize = 4096 
filename = "flatfiletransfermethod.wav"
threshold = 500 
modeltype = "medium"

while True:
    y=50
    x=400
    words_to_scribe = ""
    for event in pygame.event.get():
        if event.type==pygame.QUIT:

            pygame.quit()
            exit()

    if not lock.locked():

        lock.acquire()
        try:


            if len(buffer) > 1:

                    wav_file_info =  wave.open("flatfiletransfermethod.wav", 'wb')
                        
                    audioObj = pyaudio.PyAudio()
                    audioStream = audioObj.open(format=sample_format,
                                    channels=channels,
                                    rate=sample_rate,
                                    output=True,
                                    frames_per_buffer=chunksize)

                    wav_file_info.setnchannels(1)
                    wav_file_info.setsampwidth(audioObj.get_sample_size(pyaudio.paInt16))
                    wav_file_info.setframerate(44100)
                    wav_file_info.writeframes(b''.join(buffer))

                    wav_file_info.close()                    

                    segments, info = model.transcribe("flatfiletransfermethod.wav", beam_size=1, best_of=1, patience=1)

                    for segment in segments:
                        words_to_scribe += segment.text

                    buffer.clear()
        finally:
            lock.release()
            time.sleep(0.01)

    if words_to_scribe !=  "":

        print(words_to_scribe)
        screen.blit(background,(0,0))

        '''Decision to use textwrapper inspired by Stack Overflow'''

        text_wrapper = textwrap.TextWrapper(width=70)

        words_to_scribe = text_wrapper.wrap(words_to_scribe)

        for line in words_to_scribe:
            text_surface_Background1=font_set.render(line, True, "Black")
            text_surface=font_set.render(line, True, "White")

            #Inspired by Chatgpt
            for thickness in range(3):
                
                screen.blit(text_surface_Background1, text_surface_Background1.get_rect(center=(x,y+thickness)))
                screen.blit(text_surface_Background1, text_surface_Background1.get_rect(center=(x+thickness,y+thickness)))
                screen.blit(text_surface_Background1, text_surface_Background1.get_rect(center=(x-thickness,y+thickness)))
                screen.blit(text_surface_Background1, text_surface_Background1.get_rect(center=(x,y-thickness)))
                screen.blit(text_surface_Background1, text_surface_Background1.get_rect(center=(x+thickness,y-thickness)))
                screen.blit(text_surface_Background1, text_surface_Background1.get_rect(center=(x-thickness,y-thickness)))
                screen.blit(text_surface_Background1, text_surface_Background1.get_rect(center=(x-thickness,y)))
                screen.blit(text_surface_Background1, text_surface_Background1.get_rect(center=(x-thickness,y+thickness)))
                screen.blit(text_surface_Background1, text_surface_Background1.get_rect(center=(x-thickness,y-thickness)))
                screen.blit(text_surface_Background1, text_surface_Background1.get_rect(center=(x+thickness,y)))
                screen.blit(text_surface_Background1, text_surface_Background1.get_rect(center=(x+thickness,y+thickness)))
                screen.blit(text_surface_Background1, text_surface_Background1.get_rect(center=(x+thickness,y-thickness)))

            screen.blit(text_surface, text_surface.get_rect(center=(400,y)))
            y+=50
    pygame.display.update()
    clock.tick(1)


